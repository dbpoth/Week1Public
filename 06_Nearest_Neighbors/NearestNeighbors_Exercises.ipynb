{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Nearest Neighbors Exercises",
   "metadata": {
    "colab_type": "text",
    "id": "3hHvV20eD58o",
    "cell_id": "00000-c2e7636f-01eb-4539-9615-f462e6f2f682",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "z1h_AAj_D4kX",
    "colab": {},
    "cell_id": "00001-f904f2ff-f49d-4cf5-a2bf-8f8d4d09a9f4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ab7040a7",
    "execution_start": 1625672235196,
    "execution_millis": 3596,
    "deepnote_cell_type": "code"
   },
   "source": "import numpy as np\nimport pandas as po\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 1\n\nConsider the following simple data-set:\n\n<img src=\"https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/Images/Week1/knn_notebook_example_table.png\" alt=\"Example Table\" width=\"600\">\n\nNow consider the Sample:\n    $$X= 4, Y = 4, Z = 2$$",
   "metadata": {
    "id": "87tmgzNMb9tV",
    "colab_type": "text",
    "cell_id": "00002-2beb2222-d4f3-4315-93f0-65c78469f97c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Using kNN, what is the class for this sample for $k = 1$ and $k = 3?$ Use the Eucledian metric.\n\nFor $k = 1$, the sample is class 1. For $k = 3$, the sample is class 2.\n",
   "metadata": {
    "colab_type": "text",
    "id": "gqjait37Qws0",
    "cell_id": "00003-18cde72a-8ca0-4c0d-b013-47e1989dbbb6",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 2\nEarlier in the tutorial we were told that kNN depends on several factors, one of them being $k$. Consider the following datasets below, find the optimal value of $k$ that gives the highest accuracy. Visualize your data! Can you come up with some rule for getting a good idea of what $k$ is? \n\nHINT: look for a pattern/bound! Answer should be in terms of the size of the dataset $n$. ",
   "metadata": {
    "colab_type": "text",
    "id": "MtE0uiKuTWsI",
    "cell_id": "00004-1e5b3c66-acca-4989-9b28-d291cabf73b5",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aapncOgUo_5r",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00005-5ace4d9e-53cb-4a41-984a-68dc97516054",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "62cf56d6",
    "execution_start": 1625673244653,
    "execution_millis": 25,
    "deepnote_cell_type": "code"
   },
   "source": "# Solve this problem for each of these datasets\nfrom sklearn.datasets import load_iris \nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.datasets import load_wine \n\n# Load those datasets into some easily accessible variables\n# The datasets are already normalized, so that saves us some steps!\niris = load_iris()                    #iris dataset: size = 150\nbreast_cancer = load_breast_cancer()  #diabetes dataset: size = 569\nwine = load_wine()                    #wine dataset: size 178\n\n# This function will perfom KNN classification for a specified k\ndef split_train_test_dataset(dataset, k, test_size=0.2):\n    \"\"\"Loads and performs KNN classification on the provided dataset\"\"\"\n    # Grab and split the dataset\n    X_train, X_val, y_train, y_val = train_test_split(\n        dataset.data, dataset.target, test_size=test_size, random_state=0)\n\n    # Build a KNN classifier, fit it and test its predictions\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    acc = accuracy_score(y_val, knn.predict(X_val))\n    return acc\n    #print(k, \"Validation Accuracy is {:5.1%}\".format(\n        #accuracy_score(y_val, knn.predict(X_val))))\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lQk-b90Kgz-S",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00006-e64c614d-ef64-4987-be50-dc0a108ff803",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "dcbb9360",
    "execution_start": 1625674169472,
    "execution_millis": 603,
    "deepnote_cell_type": "code"
   },
   "source": "# YOUR CODE HERE\nval = []\nfor k in np.arange(1, 120):\n    val.append(split_train_test_dataset(iris, k))\n#val\n\n",
   "outputs": [
    {
     "name": "stdout",
     "text": "1 Validation Accuracy is 100.0%\n2 Validation Accuracy is 96.7%\n3 Validation Accuracy is 96.7%\n4 Validation Accuracy is 100.0%\n5 Validation Accuracy is 96.7%\n6 Validation Accuracy is 100.0%\n7 Validation Accuracy is 100.0%\n8 Validation Accuracy is 100.0%\n9 Validation Accuracy is 100.0%\n10 Validation Accuracy is 100.0%\n11 Validation Accuracy is 100.0%\n12 Validation Accuracy is 100.0%\n13 Validation Accuracy is 100.0%\n14 Validation Accuracy is 100.0%\n15 Validation Accuracy is 100.0%\n16 Validation Accuracy is 100.0%\n17 Validation Accuracy is 100.0%\n18 Validation Accuracy is 100.0%\n19 Validation Accuracy is 100.0%\n20 Validation Accuracy is 100.0%\n21 Validation Accuracy is 100.0%\n22 Validation Accuracy is 100.0%\n23 Validation Accuracy is 100.0%\n24 Validation Accuracy is 100.0%\n25 Validation Accuracy is 100.0%\n26 Validation Accuracy is 96.7%\n27 Validation Accuracy is 93.3%\n28 Validation Accuracy is 96.7%\n29 Validation Accuracy is 96.7%\n30 Validation Accuracy is 96.7%\n31 Validation Accuracy is 93.3%\n32 Validation Accuracy is 90.0%\n33 Validation Accuracy is 93.3%\n34 Validation Accuracy is 96.7%\n35 Validation Accuracy is 93.3%\n36 Validation Accuracy is 93.3%\n37 Validation Accuracy is 93.3%\n38 Validation Accuracy is 93.3%\n39 Validation Accuracy is 93.3%\n40 Validation Accuracy is 93.3%\n41 Validation Accuracy is 93.3%\n42 Validation Accuracy is 93.3%\n43 Validation Accuracy is 93.3%\n44 Validation Accuracy is 93.3%\n45 Validation Accuracy is 93.3%\n46 Validation Accuracy is 90.0%\n47 Validation Accuracy is 90.0%\n48 Validation Accuracy is 86.7%\n49 Validation Accuracy is 90.0%\n50 Validation Accuracy is 86.7%\n51 Validation Accuracy is 90.0%\n52 Validation Accuracy is 90.0%\n53 Validation Accuracy is 90.0%\n54 Validation Accuracy is 90.0%\n55 Validation Accuracy is 90.0%\n56 Validation Accuracy is 90.0%\n57 Validation Accuracy is 90.0%\n58 Validation Accuracy is 90.0%\n59 Validation Accuracy is 93.3%\n60 Validation Accuracy is 90.0%\n61 Validation Accuracy is 90.0%\n62 Validation Accuracy is 90.0%\n63 Validation Accuracy is 90.0%\n64 Validation Accuracy is 90.0%\n65 Validation Accuracy is 90.0%\n66 Validation Accuracy is 90.0%\n67 Validation Accuracy is 90.0%\n68 Validation Accuracy is 90.0%\n69 Validation Accuracy is 80.0%\n70 Validation Accuracy is 80.0%\n71 Validation Accuracy is 80.0%\n72 Validation Accuracy is 83.3%\n73 Validation Accuracy is 83.3%\n74 Validation Accuracy is 83.3%\n75 Validation Accuracy is 70.0%\n76 Validation Accuracy is 66.7%\n77 Validation Accuracy is 66.7%\n78 Validation Accuracy is 63.3%\n79 Validation Accuracy is 60.0%\n80 Validation Accuracy is 60.0%\n81 Validation Accuracy is 60.0%\n82 Validation Accuracy is 60.0%\n83 Validation Accuracy is 60.0%\n84 Validation Accuracy is 60.0%\n85 Validation Accuracy is 63.3%\n86 Validation Accuracy is 63.3%\n87 Validation Accuracy is 60.0%\n88 Validation Accuracy is 60.0%\n89 Validation Accuracy is 60.0%\n90 Validation Accuracy is 60.0%\n91 Validation Accuracy is 60.0%\n92 Validation Accuracy is 60.0%\n93 Validation Accuracy is 56.7%\n94 Validation Accuracy is 56.7%\n95 Validation Accuracy is 56.7%\n96 Validation Accuracy is 56.7%\n97 Validation Accuracy is 56.7%\n98 Validation Accuracy is 56.7%\n99 Validation Accuracy is 56.7%\n100 Validation Accuracy is 56.7%\n101 Validation Accuracy is 56.7%\n102 Validation Accuracy is 56.7%\n103 Validation Accuracy is 56.7%\n104 Validation Accuracy is 56.7%\n105 Validation Accuracy is 56.7%\n106 Validation Accuracy is 56.7%\n107 Validation Accuracy is 56.7%\n108 Validation Accuracy is 56.7%\n109 Validation Accuracy is 56.7%\n110 Validation Accuracy is 56.7%\n111 Validation Accuracy is 56.7%\n112 Validation Accuracy is 56.7%\n113 Validation Accuracy is 56.7%\n114 Validation Accuracy is 56.7%\n115 Validation Accuracy is 56.7%\n116 Validation Accuracy is 20.0%\n117 Validation Accuracy is 20.0%\n118 Validation Accuracy is 20.0%\n119 Validation Accuracy is 20.0%\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 51,
     "data": {
      "text/plain": "[None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None]"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Write a single mathematical expression describing the relationship you found between $n$ (the size of the dataset) and $k$ (the number of datapoints used to classify each validation datum).",
   "metadata": {
    "id": "n1_EbFlqzjAT",
    "colab_type": "text",
    "cell_id": "00007-9e31e134-f849-45d6-980b-81094c4e074f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "There was not a clear trend for these data sets. For example, the iris data set with 120 values needed a lower k value for higher accuracy, and for the breast_cancer data set the optimal k value was still lower even with 569 values. ",
   "metadata": {
    "id": "PbbrX6rGq6CV",
    "colab_type": "text",
    "cell_id": "00008-01630e1e-58e1-480d-b182-928216e4dc1d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 3\nNow, we will **be writing our k-NNA**. Recall that we said a kNN is comprised of a predictions and using those predictions to classify the data. Here we will try to mimic sklearn's kNN methods. We will be using the Pima diabetes dataset. ",
   "metadata": {
    "colab_type": "text",
    "id": "-vDZy0F3eyeH",
    "cell_id": "00009-6b713464-0106-4edd-946f-132b72febf84",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Loading and splitting data",
   "metadata": {
    "id": "8YFfjG9G3lVO",
    "colab_type": "text",
    "cell_id": "00010-84a30058-7b6a-4895-b6d3-3c2289005067",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "zbs8WICFgITd",
    "colab": {},
    "cell_id": "00011-1c057c97-58b6-4874-80b7-10c7451fa29c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ac1b2bb9",
    "execution_start": 1625673610566,
    "execution_millis": 97,
    "deepnote_cell_type": "code"
   },
   "source": "url = \"https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week1/diabetes.csv\"\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndata = po.read_csv(url, names=names)\n\n# Dropping NaN rows\ninvalid = ['plas', 'pres', 'skin', 'test', 'mass']\n\nfor i in invalid:\n    data[i].replace(to_replace=0, value=np.nan, inplace=True)\n    \ndata = data.dropna(axis=0).reset_index(drop=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Now, let's clearly define which columns will act as explanatory variables, and which column will be the target value, and split the dataset between your training data and testing data. Let's try an 80-20 split and use sklearn's [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method (set random_state = 0 so we get the same output each time).",
   "metadata": {
    "id": "aSUwHL6-4P2F",
    "colab_type": "text",
    "cell_id": "00012-edbb2bcc-a36e-4f35-82dc-f76f34842e05",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "9MXZjxRcgy78",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "91bb35f5-9c29-4c6b-dbba-7a0644a3e2ca",
    "cell_id": "00013-92ad0b5c-3054-4097-b3ae-6285d5b03669",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d98a6cd6",
    "execution_start": 1625673666458,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "# Columns we will use to make predictions with (features!) feel free to play around with these\nX_cols = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']\n\n# Column that we want to predict (the labels)\ny_col = 'class'\n\n# 80-20 train-test split of datset\ntest_size = 0.2\nX_train, X_test, y_train, y_test = train_test_split(data[X_cols], data[y_col], test_size=test_size, random_state=0)\n\n# Further split X and y of training into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=0)\n\nprint('There are {} training samples with {} features and {} associated classification labels'.format(*X_train.shape, *y_train.shape))\nprint('There are {} validation samples with {} features and {} associated classification labels'.format(*X_val.shape, *y_val.shape))\nprint('There are {} test samples with {} features and {} associated classification labels'.format(*X_test.shape, *y_test.shape))",
   "outputs": [
    {
     "name": "stdout",
     "text": "There are 250 training samples with 8 features and 250 associated classification labels\nThere are 63 validation samples with 8 features and 63 associated classification labels\nThere are 79 test samples with 8 features and 79 associated classification labels\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00014-4501085a-6d5c-412b-9b1d-34bea6178ae3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ab64df91",
    "execution_start": 1625683284899,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 104,
     "data": {
      "text/plain": "numpy.float64"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Normalizing Data\n\nLet's not forget to normalize the data! We'll use sklearn's StandardScaler normalization like we did before to normalize the training **and** validation/data.",
   "metadata": {
    "colab_type": "text",
    "id": "De_EJnYKgz_6",
    "cell_id": "00014-d3d19f71-9aab-4cb2-a5bc-bd51c048aaab",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "6PD6-ibriBJO",
    "colab": {},
    "cell_id": "00015-3c4b33fb-bf48-4a47-888f-26f963243ca1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "844e8ff7",
    "execution_start": 1625673825470,
    "execution_millis": 10,
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nfor i in list(X_train):\n    feature_data_train = X_train[i].values.reshape(-1, 1)\n    scaler.fit(feature_data_train)\n    X_train[i] = scaler.transform(feature_data_train)\n\nfor j in list(X_test):\n    feature_data_test = X_test[j].values.reshape(-1, 1)\n    scaler.fit(feature_data_test)\n    X_test[j] = scaler.transform(feature_data_test)\n    \nfor k in list(X_val):\n    feature_data_val = X_val[k].values.reshape(-1, 1)\n    scaler.fit(feature_data_val)\n    X_val[k] = scaler.transform(feature_data_val)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Writing your kNN\n\nNow for the fun part! Fill in the 3 following methods, euclidean_dist(), predict(), and knn().\n\nThe predict method that we'll make below needs to: \n1. Compute the euclidean distance between the “new” observation and all the data points in the training set. \n2. Assign the corresponding label to the observation\n3. Select the k nearest ones and perform a \"majority vote\"",
   "metadata": {
    "colab_type": "text",
    "id": "hnv61aiiitxU",
    "cell_id": "00016-936a23e0-5940-4cd3-bfbf-f65294228af4",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xXkIw6zN3lVb",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00017-14b68561-0190-4b35-9b04-3b33196a69b9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "60476e7a",
    "execution_start": 1625684124618,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "# Euclidean distance function from tutorial\ndef euclidean_dist(datum1, datum2):\n    inner_val = 0.0\n    \n    for g in range(datum1.shape[0]):\n        inner_val += (datum1[g]- datum2[g]) ** 2\n    \n    distance = np.sqrt(inner_val)\n    \n    return(distance)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "type(X_train.iloc[0])",
   "metadata": {
    "tags": [],
    "cell_id": "00018-c47d5332-9cf8-483d-a5e8-0d695d9b5e4d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4e7b67f6",
    "execution_start": 1625682832270,
    "execution_millis": 11,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 95,
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "FqJkm_ytjFgM",
    "colab": {},
    "cell_id": "00018-7a3be6d5-55b3-4735-9047-9e5f47a66054",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "eb124fe9",
    "execution_start": 1625684223100,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "source": "from collections import Counter\n\ndef predict(x_training, y_training, x_test_sample, k):\n    \n    # Create list for distances and targets\n    distances = []\n    targets = []\n\n    # YOUR CODE HERE\n\n    #ix_training = x_training.index\n    \n    for i in list(x_training.index):\n        cur_dist = [euclidean_dist(x_training.loc[i], x_test_sample), i]\n        distances.append(cur_dist)\n    \n    distances = sorted(distances)\n    \n    for i in range(k):\n        var = distances[i][1]\n        targets.append(y_training.loc[var])\n            \n    return Counter(targets).most_common()[0][0]\n\n#predict(po.DataFrame([[1],[2],[3],[2],[5]]), po.DataFrame([[6],[7],[3],[1],[7]]), 4, 3)\n\n#predict(X_train, y_train, X_val.loc[0], k=5)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# 1. compute distance - complete\n# 2. assign label to observation\n# 3. select the k nearest ones\n# 4. majority vote (Counter)",
   "metadata": {
    "tags": [],
    "cell_id": "00019-c3ed8e65-df4f-474d-89af-5c93c0d41898",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "860ec32c",
    "execution_start": 1625684223526,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BguZLcRa3lVh",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00019-0630ca1e-0300-4f0e-8a92-1b703be12bbe",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "10be6a54",
    "execution_start": 1625684223865,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": "def knn(x_training, y_training, x_testing, k):\n    \n    # YOUR CODE HERE\n    \n    point_preds = []\n\n    for i in list(x_testing.index):\n        point_pred = predict(x_training, y_training, x_testing.loc[i], k)\n        point_preds.append(point_pred)\n\n    return point_preds",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "When done, test your code by running the methods here!",
   "metadata": {
    "colab_type": "text",
    "id": "4uhQZPIpjdo9",
    "cell_id": "00020-cfffd903-553f-4ecc-8220-5636a082d81a",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "AHRJXVr7jcao",
    "colab": {},
    "cell_id": "00021-89b4af94-0959-47b8-ac7a-1c2f48e40679",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "411446fa",
    "execution_start": 1625684225251,
    "execution_millis": 5912,
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.metrics import accuracy_score\nimport time\n\nstart = time.time()\npredictions_slow = knn(X_train, y_train, X_val, k=5)\n\nprint('Took {} seconds'.format(time.time() - start))\nprint(\"Validation Accuracy is \", accuracy_score(y_val,predictions_slow)*100)",
   "outputs": [
    {
     "name": "stdout",
     "text": "Took 5.829665660858154 seconds\nValidation Accuracy is  80.95238095238095\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Check sklearn's predictions on validation data from the tutorial notebook and make sure they match yours. Sklearn is faster, but you should get the same answers.",
   "metadata": {
    "id": "2a51RcbJ3lVq",
    "colab_type": "text",
    "cell_id": "00022-4a85eefc-cd74-4a60-894d-aa845d36111f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00026-efee406b-ef58-4f9b-8a68-d290d5ea17ee",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6eb312d5-62b7-42e3-a19a-ad8b15b7fa98' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "NearestNeighbors_Exercises",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "deepnote_notebook_id": "9b6a0168-bffb-4750-b7a9-565c6addf8e5",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}